{
  "best_metric": 0.10427526384592056,
  "best_model_checkpoint": "./results/checkpoint-5064",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 5064,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06,
      "grad_norm": 4.197818279266357,
      "learning_rate": 9.802527646129542e-05,
      "loss": 0.1774,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.157414436340332,
      "learning_rate": 9.605055292259084e-05,
      "loss": 0.1796,
      "step": 200
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.584421157836914,
      "learning_rate": 9.407582938388626e-05,
      "loss": 0.1757,
      "step": 300
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4414334297180176,
      "learning_rate": 9.210110584518168e-05,
      "loss": 0.181,
      "step": 400
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.316088676452637,
      "learning_rate": 9.01263823064771e-05,
      "loss": 0.1707,
      "step": 500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8933937549591064,
      "learning_rate": 8.815165876777251e-05,
      "loss": 0.1748,
      "step": 600
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.3098771572113037,
      "learning_rate": 8.617693522906793e-05,
      "loss": 0.1764,
      "step": 700
    },
    {
      "epoch": 0.47,
      "grad_norm": 4.737509727478027,
      "learning_rate": 8.420221169036335e-05,
      "loss": 0.1731,
      "step": 800
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.761893630027771,
      "learning_rate": 8.222748815165877e-05,
      "loss": 0.1677,
      "step": 900
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.127511739730835,
      "learning_rate": 8.025276461295419e-05,
      "loss": 0.16,
      "step": 1000
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.307400703430176,
      "learning_rate": 7.82780410742496e-05,
      "loss": 0.1714,
      "step": 1100
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.630842208862305,
      "learning_rate": 7.630331753554502e-05,
      "loss": 0.1519,
      "step": 1200
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5916786193847656,
      "learning_rate": 7.432859399684044e-05,
      "loss": 0.1714,
      "step": 1300
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.165269613265991,
      "learning_rate": 7.235387045813586e-05,
      "loss": 0.1558,
      "step": 1400
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.388113260269165,
      "learning_rate": 7.037914691943128e-05,
      "loss": 0.161,
      "step": 1500
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.073533058166504,
      "learning_rate": 6.84044233807267e-05,
      "loss": 0.1571,
      "step": 1600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9555,
      "eval_f1": 0.9515787214141784,
      "eval_loss": 0.13601337373256683,
      "eval_precision": 0.9523278664568879,
      "eval_recall": 0.951039161505256,
      "eval_runtime": 16.5753,
      "eval_samples_per_second": 7239.705,
      "eval_steps_per_second": 113.12,
      "step": 1688
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.914041042327881,
      "learning_rate": 6.642969984202211e-05,
      "loss": 0.155,
      "step": 1700
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.237450122833252,
      "learning_rate": 6.445497630331754e-05,
      "loss": 0.1251,
      "step": 1800
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.5035040378570557,
      "learning_rate": 6.248025276461296e-05,
      "loss": 0.1332,
      "step": 1900
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.59698486328125,
      "learning_rate": 6.0505529225908374e-05,
      "loss": 0.1291,
      "step": 2000
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.6553704738616943,
      "learning_rate": 5.853080568720379e-05,
      "loss": 0.1388,
      "step": 2100
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.1993446350097656,
      "learning_rate": 5.655608214849921e-05,
      "loss": 0.1267,
      "step": 2200
    },
    {
      "epoch": 1.36,
      "grad_norm": 4.715301990509033,
      "learning_rate": 5.458135860979463e-05,
      "loss": 0.1351,
      "step": 2300
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.4400253295898438,
      "learning_rate": 5.260663507109005e-05,
      "loss": 0.1249,
      "step": 2400
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.08159065246582,
      "learning_rate": 5.0631911532385465e-05,
      "loss": 0.1286,
      "step": 2500
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.7968543767929077,
      "learning_rate": 4.865718799368088e-05,
      "loss": 0.1233,
      "step": 2600
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.7374212741851807,
      "learning_rate": 4.668246445497631e-05,
      "loss": 0.1449,
      "step": 2700
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.050208568572998,
      "learning_rate": 4.4707740916271726e-05,
      "loss": 0.1257,
      "step": 2800
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2630258798599243,
      "learning_rate": 4.2733017377567144e-05,
      "loss": 0.1314,
      "step": 2900
    },
    {
      "epoch": 1.78,
      "grad_norm": 5.212799072265625,
      "learning_rate": 4.075829383886256e-05,
      "loss": 0.1235,
      "step": 3000
    },
    {
      "epoch": 1.84,
      "grad_norm": 4.830326080322266,
      "learning_rate": 3.878357030015798e-05,
      "loss": 0.1281,
      "step": 3100
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.5698046684265137,
      "learning_rate": 3.68088467614534e-05,
      "loss": 0.1334,
      "step": 3200
    },
    {
      "epoch": 1.95,
      "grad_norm": 6.416478633880615,
      "learning_rate": 3.4834123222748817e-05,
      "loss": 0.1411,
      "step": 3300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9641583333333333,
      "eval_f1": 0.9608912941070648,
      "eval_loss": 0.11109820008277893,
      "eval_precision": 0.9611030431436367,
      "eval_recall": 0.9607922632720381,
      "eval_runtime": 16.101,
      "eval_samples_per_second": 7452.969,
      "eval_steps_per_second": 116.453,
      "step": 3376
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.3641655445098877,
      "learning_rate": 3.2859399684044235e-05,
      "loss": 0.1168,
      "step": 3400
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.9868282079696655,
      "learning_rate": 3.088467614533965e-05,
      "loss": 0.1258,
      "step": 3500
    },
    {
      "epoch": 2.13,
      "grad_norm": 4.629307270050049,
      "learning_rate": 2.890995260663507e-05,
      "loss": 0.1204,
      "step": 3600
    },
    {
      "epoch": 2.19,
      "grad_norm": 6.7778472900390625,
      "learning_rate": 2.693522906793049e-05,
      "loss": 0.1184,
      "step": 3700
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.498602867126465,
      "learning_rate": 2.4960505529225907e-05,
      "loss": 0.1186,
      "step": 3800
    },
    {
      "epoch": 2.31,
      "grad_norm": 3.204089403152466,
      "learning_rate": 2.2985781990521325e-05,
      "loss": 0.1145,
      "step": 3900
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.003213405609131,
      "learning_rate": 2.1011058451816747e-05,
      "loss": 0.1281,
      "step": 4000
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.562333822250366,
      "learning_rate": 1.9036334913112165e-05,
      "loss": 0.1163,
      "step": 4100
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.0898497104644775,
      "learning_rate": 1.7061611374407587e-05,
      "loss": 0.1128,
      "step": 4200
    },
    {
      "epoch": 2.55,
      "grad_norm": 4.194226264953613,
      "learning_rate": 1.5086887835703003e-05,
      "loss": 0.1173,
      "step": 4300
    },
    {
      "epoch": 2.61,
      "grad_norm": 1.4798698425292969,
      "learning_rate": 1.3112164296998423e-05,
      "loss": 0.1157,
      "step": 4400
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.924750328063965,
      "learning_rate": 1.113744075829384e-05,
      "loss": 0.1283,
      "step": 4500
    },
    {
      "epoch": 2.73,
      "grad_norm": 4.349680423736572,
      "learning_rate": 9.162717219589257e-06,
      "loss": 0.1143,
      "step": 4600
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.833766460418701,
      "learning_rate": 7.187993680884676e-06,
      "loss": 0.1206,
      "step": 4700
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.8816697597503662,
      "learning_rate": 5.2132701421800945e-06,
      "loss": 0.1098,
      "step": 4800
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.211615800857544,
      "learning_rate": 3.2385466034755135e-06,
      "loss": 0.115,
      "step": 4900
    },
    {
      "epoch": 2.96,
      "grad_norm": 5.685185432434082,
      "learning_rate": 1.263823064770932e-06,
      "loss": 0.1126,
      "step": 5000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9667333333333333,
      "eval_f1": 0.9637023002755987,
      "eval_loss": 0.10427526384592056,
      "eval_precision": 0.9641532214429217,
      "eval_recall": 0.9634819854617556,
      "eval_runtime": 16.0938,
      "eval_samples_per_second": 7456.306,
      "eval_steps_per_second": 116.505,
      "step": 5064
    }
  ],
  "logging_steps": 100,
  "max_steps": 5064,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 205947297792000.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
